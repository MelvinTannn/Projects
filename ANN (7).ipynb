{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jawaban No.4 UTS - ANN - Melvin - 2301863263.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGuV8HdiGU7h"
      },
      "source": [
        "#!pip install --upgrade tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WCDC6fBHCZb"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import SimpleRNNCell, RNN, Dense\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIHpWGVWHFaD"
      },
      "source": [
        "df = pd.read_csv('USD_INR.csv')\n",
        "changes = df['Change %'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDQ6ZBlPHwag"
      },
      "source": [
        "train_ch, test_ch = train_test_split(changes, test_size = 0.2, shuffle = False, random_state = 1)\n",
        "\n",
        "train_ch = train_ch.reshape(-1,1)\n",
        "test_ch = test_ch.reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKtQBd0sIj2D"
      },
      "source": [
        "#Normalize Dataset\n",
        "scaler = StandardScaler().fit(train_ch)\n",
        "train_ch = scaler.transform(train_ch)\n",
        "test_ch = scaler.transform(test_ch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDhqgMcrJxgN"
      },
      "source": [
        "timestep = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97FH8J4kJIlk"
      },
      "source": [
        "Disini saya menentukan timestep sebesar 30 karena 30 rata - rata jumlah hari dalam bulan adalah 30-31 hari"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4036GxIlJ3NI",
        "outputId": "542b8eef-f988-41ea-ce71-a2b1c9a3c932"
      },
      "source": [
        "#mengecek ukuran dimensi training\n",
        "train_ch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7757, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SeuhMCrJ7Uk"
      },
      "source": [
        "def construct_dataset(in_prices):\n",
        "  features = []\n",
        "  targets = []\n",
        "\n",
        "  for i in range(timestep, in_prices.shape[0]):\n",
        "    features.append(\n",
        "        in_prices[i - timestep : i]\n",
        "    )\n",
        "    targets.append(\n",
        "        in_prices[i]\n",
        "    )\n",
        "    features = np.array(features, 'float32')\n",
        "    targets = np.array(targets, 'float32')\n",
        "\n",
        "    return features, targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpaNGBxsKX98"
      },
      "source": [
        "x_train, y_train = construct_dataset(train_ch)\n",
        "x_test, y_test = construct_dataset(test_ch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WVk9yUoKgBx"
      },
      "source": [
        "input_placeholder = tf.placeholder(tf.float32, [None, timestep, 1])\n",
        "target_placeholder = tf.placeholder(tf.float32, [None, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCBjpHQLKjmJ"
      },
      "source": [
        "cell = SimpleRNNCell(64, activation='relu')\n",
        "\n",
        "rnn_layer = RNN(cell, dtype=tf.float32)\n",
        "output_layer = Dense(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xF5PhJOtKlVn",
        "outputId": "b3fd66b1-6113-4f65-8241-a5088c8010cc"
      },
      "source": [
        "out_tensor = rnn_layer(input_placeholder)\n",
        "out_tensor = output_layer(out_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIXYureJKlLm"
      },
      "source": [
        "# mse\n",
        "loss_tensor = tf.reduce_mean(0.5 * (out_tensor - target_placeholder)**2)\n",
        "\n",
        "# optimal rmse (root mean squared error)\n",
        "rmse_tensor = tf.reduce_mean(tf.sqrt(0.5 * (out_tensor - target_placeholder)**2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmcd0_z1KpG6",
        "outputId": "193aa8b1-1966-4370-8870-2d2637ef3b0e"
      },
      "source": [
        "optimizer = tf.train.AdamOptimizer().minimize(loss_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFksCyqkKqdf"
      },
      "source": [
        "saver = tf.train.Saver()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEbU6Qk0Kr6A"
      },
      "source": [
        "num_epoch = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmJMTj-6KuYV",
        "outputId": "a16ef474-8743-4690-8625-9c22129c0b03"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  train_dict = {\n",
        "      input_placeholder:x_train,\n",
        "      target_placeholder:y_train\n",
        "  }\n",
        "  test_dict = {\n",
        "      input_placeholder:x_test,\n",
        "      target_placeholder:y_test\n",
        "  }\n",
        "\n",
        "  best_loss = float('inf')\n",
        "  for epoch in range(num_epoch):\n",
        "    sess.run(optimizer, feed_dict=train_dict)\n",
        "\n",
        "    loss = sess.run(loss_tensor, feed_dict=train_dict)\n",
        "    val_loss = sess.run(loss_tensor, feed_dict=test_dict)\n",
        "\n",
        "    rmse = sess.run(rmse_tensor, feed_dict=train_dict)\n",
        "    val_rmse = sess.run(rmse_tensor, feed_dict=test_dict)\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "      best_loss = val_loss\n",
        "      saver.save(sess, './best_model.ckpt')\n",
        "      \n",
        "    if epoch % 1 == 0:\n",
        "      print(f'Epoch {epoch+1} - loss {loss:.4f} - rmse {rmse:.4f} - val_loss {val_loss:.4f} - val_rmse {val_rmse:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 - loss 0.1634 - rmse 0.4042 - val_loss 0.0000 - val_rmse 0.0017\n",
            "Epoch 2 - loss 0.1378 - rmse 0.3712 - val_loss 0.0004 - val_rmse 0.0189\n",
            "Epoch 3 - loss 0.1165 - rmse 0.3414 - val_loss 0.0013 - val_rmse 0.0360\n",
            "Epoch 4 - loss 0.0980 - rmse 0.3131 - val_loss 0.0026 - val_rmse 0.0507\n",
            "Epoch 5 - loss 0.0812 - rmse 0.2849 - val_loss 0.0041 - val_rmse 0.0644\n",
            "Epoch 6 - loss 0.0671 - rmse 0.2590 - val_loss 0.0061 - val_rmse 0.0778\n",
            "Epoch 7 - loss 0.0561 - rmse 0.2368 - val_loss 0.0080 - val_rmse 0.0892\n",
            "Epoch 8 - loss 0.0466 - rmse 0.2159 - val_loss 0.0098 - val_rmse 0.0988\n",
            "Epoch 9 - loss 0.0379 - rmse 0.1946 - val_loss 0.0118 - val_rmse 0.1085\n",
            "Epoch 10 - loss 0.0302 - rmse 0.1738 - val_loss 0.0137 - val_rmse 0.1171\n",
            "Epoch 11 - loss 0.0233 - rmse 0.1528 - val_loss 0.0160 - val_rmse 0.1266\n",
            "Epoch 12 - loss 0.0172 - rmse 0.1311 - val_loss 0.0189 - val_rmse 0.1373\n",
            "Epoch 13 - loss 0.0121 - rmse 0.1102 - val_loss 0.0221 - val_rmse 0.1488\n",
            "Epoch 14 - loss 0.0080 - rmse 0.0895 - val_loss 0.0262 - val_rmse 0.1619\n",
            "Epoch 15 - loss 0.0048 - rmse 0.0692 - val_loss 0.0309 - val_rmse 0.1758\n",
            "Epoch 16 - loss 0.0024 - rmse 0.0486 - val_loss 0.0359 - val_rmse 0.1895\n",
            "Epoch 17 - loss 0.0007 - rmse 0.0272 - val_loss 0.0421 - val_rmse 0.2052\n",
            "Epoch 18 - loss 0.0000 - rmse 0.0061 - val_loss 0.0495 - val_rmse 0.2224\n",
            "Epoch 19 - loss 0.0002 - rmse 0.0143 - val_loss 0.0575 - val_rmse 0.2398\n",
            "Epoch 20 - loss 0.0011 - rmse 0.0332 - val_loss 0.0658 - val_rmse 0.2564\n",
            "Epoch 21 - loss 0.0023 - rmse 0.0478 - val_loss 0.0726 - val_rmse 0.2694\n",
            "Epoch 22 - loss 0.0032 - rmse 0.0567 - val_loss 0.0763 - val_rmse 0.2763\n",
            "Epoch 23 - loss 0.0036 - rmse 0.0596 - val_loss 0.0772 - val_rmse 0.2779\n",
            "Epoch 24 - loss 0.0034 - rmse 0.0584 - val_loss 0.0757 - val_rmse 0.2751\n",
            "Epoch 25 - loss 0.0029 - rmse 0.0539 - val_loss 0.0728 - val_rmse 0.2697\n",
            "Epoch 26 - loss 0.0023 - rmse 0.0475 - val_loss 0.0693 - val_rmse 0.2633\n",
            "Epoch 27 - loss 0.0015 - rmse 0.0393 - val_loss 0.0655 - val_rmse 0.2559\n",
            "Epoch 28 - loss 0.0010 - rmse 0.0309 - val_loss 0.0617 - val_rmse 0.2483\n",
            "Epoch 29 - loss 0.0005 - rmse 0.0222 - val_loss 0.0583 - val_rmse 0.2414\n",
            "Epoch 30 - loss 0.0002 - rmse 0.0136 - val_loss 0.0551 - val_rmse 0.2347\n",
            "Epoch 31 - loss 0.0000 - rmse 0.0055 - val_loss 0.0522 - val_rmse 0.2285\n",
            "Epoch 32 - loss 0.0000 - rmse 0.0014 - val_loss 0.0496 - val_rmse 0.2228\n",
            "Epoch 33 - loss 0.0001 - rmse 0.0074 - val_loss 0.0474 - val_rmse 0.2176\n",
            "Epoch 34 - loss 0.0002 - rmse 0.0124 - val_loss 0.0456 - val_rmse 0.2135\n",
            "Epoch 35 - loss 0.0003 - rmse 0.0161 - val_loss 0.0442 - val_rmse 0.2103\n",
            "Epoch 36 - loss 0.0004 - rmse 0.0188 - val_loss 0.0432 - val_rmse 0.2077\n",
            "Epoch 37 - loss 0.0004 - rmse 0.0207 - val_loss 0.0424 - val_rmse 0.2060\n",
            "Epoch 38 - loss 0.0005 - rmse 0.0216 - val_loss 0.0420 - val_rmse 0.2048\n",
            "Epoch 39 - loss 0.0005 - rmse 0.0219 - val_loss 0.0416 - val_rmse 0.2040\n",
            "Epoch 40 - loss 0.0005 - rmse 0.0214 - val_loss 0.0415 - val_rmse 0.2038\n",
            "Epoch 41 - loss 0.0004 - rmse 0.0203 - val_loss 0.0416 - val_rmse 0.2040\n",
            "Epoch 42 - loss 0.0003 - rmse 0.0186 - val_loss 0.0419 - val_rmse 0.2046\n",
            "Epoch 43 - loss 0.0003 - rmse 0.0165 - val_loss 0.0422 - val_rmse 0.2055\n",
            "Epoch 44 - loss 0.0002 - rmse 0.0140 - val_loss 0.0427 - val_rmse 0.2067\n",
            "Epoch 45 - loss 0.0001 - rmse 0.0112 - val_loss 0.0433 - val_rmse 0.2081\n",
            "Epoch 46 - loss 0.0001 - rmse 0.0084 - val_loss 0.0439 - val_rmse 0.2096\n",
            "Epoch 47 - loss 0.0000 - rmse 0.0054 - val_loss 0.0446 - val_rmse 0.2111\n",
            "Epoch 48 - loss 0.0000 - rmse 0.0026 - val_loss 0.0452 - val_rmse 0.2126\n",
            "Epoch 49 - loss 0.0000 - rmse 0.0001 - val_loss 0.0458 - val_rmse 0.2140\n",
            "Epoch 50 - loss 0.0000 - rmse 0.0026 - val_loss 0.0464 - val_rmse 0.2153\n",
            "Epoch 51 - loss 0.0000 - rmse 0.0047 - val_loss 0.0468 - val_rmse 0.2164\n",
            "Epoch 52 - loss 0.0000 - rmse 0.0065 - val_loss 0.0472 - val_rmse 0.2172\n",
            "Epoch 53 - loss 0.0001 - rmse 0.0078 - val_loss 0.0475 - val_rmse 0.2179\n",
            "Epoch 54 - loss 0.0001 - rmse 0.0088 - val_loss 0.0476 - val_rmse 0.2182\n",
            "Epoch 55 - loss 0.0001 - rmse 0.0092 - val_loss 0.0477 - val_rmse 0.2183\n",
            "Epoch 56 - loss 0.0001 - rmse 0.0093 - val_loss 0.0476 - val_rmse 0.2182\n",
            "Epoch 57 - loss 0.0001 - rmse 0.0090 - val_loss 0.0474 - val_rmse 0.2178\n",
            "Epoch 58 - loss 0.0001 - rmse 0.0083 - val_loss 0.0472 - val_rmse 0.2172\n",
            "Epoch 59 - loss 0.0001 - rmse 0.0074 - val_loss 0.0469 - val_rmse 0.2165\n",
            "Epoch 60 - loss 0.0000 - rmse 0.0062 - val_loss 0.0465 - val_rmse 0.2156\n",
            "Epoch 61 - loss 0.0000 - rmse 0.0049 - val_loss 0.0461 - val_rmse 0.2147\n",
            "Epoch 62 - loss 0.0000 - rmse 0.0035 - val_loss 0.0457 - val_rmse 0.2137\n",
            "Epoch 63 - loss 0.0000 - rmse 0.0021 - val_loss 0.0452 - val_rmse 0.2127\n",
            "Epoch 64 - loss 0.0000 - rmse 0.0008 - val_loss 0.0448 - val_rmse 0.2117\n",
            "Epoch 65 - loss 0.0000 - rmse 0.0005 - val_loss 0.0445 - val_rmse 0.2109\n",
            "Epoch 66 - loss 0.0000 - rmse 0.0016 - val_loss 0.0441 - val_rmse 0.2101\n",
            "Epoch 67 - loss 0.0000 - rmse 0.0025 - val_loss 0.0439 - val_rmse 0.2094\n",
            "Epoch 68 - loss 0.0000 - rmse 0.0032 - val_loss 0.0436 - val_rmse 0.2089\n",
            "Epoch 69 - loss 0.0000 - rmse 0.0037 - val_loss 0.0435 - val_rmse 0.2085\n",
            "Epoch 70 - loss 0.0000 - rmse 0.0040 - val_loss 0.0433 - val_rmse 0.2082\n",
            "Epoch 71 - loss 0.0000 - rmse 0.0041 - val_loss 0.0433 - val_rmse 0.2080\n",
            "Epoch 72 - loss 0.0000 - rmse 0.0040 - val_loss 0.0433 - val_rmse 0.2080\n",
            "Epoch 73 - loss 0.0000 - rmse 0.0038 - val_loss 0.0433 - val_rmse 0.2080\n",
            "Epoch 74 - loss 0.0000 - rmse 0.0034 - val_loss 0.0433 - val_rmse 0.2082\n",
            "Epoch 75 - loss 0.0000 - rmse 0.0029 - val_loss 0.0434 - val_rmse 0.2084\n",
            "Epoch 76 - loss 0.0000 - rmse 0.0024 - val_loss 0.0435 - val_rmse 0.2087\n",
            "Epoch 77 - loss 0.0000 - rmse 0.0017 - val_loss 0.0437 - val_rmse 0.2090\n",
            "Epoch 78 - loss 0.0000 - rmse 0.0011 - val_loss 0.0438 - val_rmse 0.2093\n",
            "Epoch 79 - loss 0.0000 - rmse 0.0005 - val_loss 0.0439 - val_rmse 0.2096\n",
            "Epoch 80 - loss 0.0000 - rmse 0.0001 - val_loss 0.0441 - val_rmse 0.2099\n",
            "Epoch 81 - loss 0.0000 - rmse 0.0006 - val_loss 0.0442 - val_rmse 0.2102\n",
            "Epoch 82 - loss 0.0000 - rmse 0.0011 - val_loss 0.0443 - val_rmse 0.2104\n",
            "Epoch 83 - loss 0.0000 - rmse 0.0015 - val_loss 0.0444 - val_rmse 0.2106\n",
            "Epoch 84 - loss 0.0000 - rmse 0.0017 - val_loss 0.0444 - val_rmse 0.2107\n",
            "Epoch 85 - loss 0.0000 - rmse 0.0019 - val_loss 0.0444 - val_rmse 0.2108\n",
            "Epoch 86 - loss 0.0000 - rmse 0.0019 - val_loss 0.0444 - val_rmse 0.2108\n",
            "Epoch 87 - loss 0.0000 - rmse 0.0019 - val_loss 0.0444 - val_rmse 0.2107\n",
            "Epoch 88 - loss 0.0000 - rmse 0.0017 - val_loss 0.0444 - val_rmse 0.2106\n",
            "Epoch 89 - loss 0.0000 - rmse 0.0015 - val_loss 0.0443 - val_rmse 0.2105\n",
            "Epoch 90 - loss 0.0000 - rmse 0.0013 - val_loss 0.0442 - val_rmse 0.2103\n",
            "Epoch 91 - loss 0.0000 - rmse 0.0010 - val_loss 0.0442 - val_rmse 0.2101\n",
            "Epoch 92 - loss 0.0000 - rmse 0.0007 - val_loss 0.0441 - val_rmse 0.2099\n",
            "Epoch 93 - loss 0.0000 - rmse 0.0004 - val_loss 0.0440 - val_rmse 0.2097\n",
            "Epoch 94 - loss 0.0000 - rmse 0.0001 - val_loss 0.0439 - val_rmse 0.2096\n",
            "Epoch 95 - loss 0.0000 - rmse 0.0002 - val_loss 0.0438 - val_rmse 0.2094\n",
            "Epoch 96 - loss 0.0000 - rmse 0.0005 - val_loss 0.0438 - val_rmse 0.2092\n",
            "Epoch 97 - loss 0.0000 - rmse 0.0007 - val_loss 0.0437 - val_rmse 0.2091\n",
            "Epoch 98 - loss 0.0000 - rmse 0.0008 - val_loss 0.0437 - val_rmse 0.2090\n",
            "Epoch 99 - loss 0.0000 - rmse 0.0009 - val_loss 0.0437 - val_rmse 0.2090\n",
            "Epoch 100 - loss 0.0000 - rmse 0.0009 - val_loss 0.0436 - val_rmse 0.2089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4x6aFztKqT_"
      },
      "source": [
        "Saya menggunakan rmse metrics untuk mengevaluasi hasil yang didapatkan bisa dilihat bahwa value dari rmse yang dihasilkan bertambah dari 0.0289 pada epoch 1 sampai 0.1231 pada epoch 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88XHRHjnOAeh"
      },
      "source": [
        "x = changes[-30:]\n",
        "x = x.reshape(-1, 1)\n",
        "x = scaler.transform(x)\n",
        "x = np.array([x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsOF-q9TODHI",
        "outputId": "72eb1a9a-fb2f-42a7-bd15-6ad231d05232"
      },
      "source": [
        "changes[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aB3_0cCOFIn",
        "outputId": "4e4906a7-98f3-47f5-8a72-92a1b2186782"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  saver.restore(sess, './best_model.ckpt')\n",
        "\n",
        "  pred = sess.run(out_tensor, feed_dict={input_placeholder:x})\n",
        "  pred = scaler.inverse_transform(pred)\n",
        "  print(f'USD to IRP Next Exchange Rate: {pred}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./best_model.ckpt\n",
            "USD to IRP Next Exchange Rate: [[-0.09903964]]%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0P1ChpmLlnp"
      },
      "source": [
        "dari hasil diatas bahwa dapat dilihat prediksi exchange rate selanjutnya "
      ]
    }
  ]
}